{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584461af-422f-455a-9db9-77683b7235c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Data ready. Shape: (68875, 37)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Data Loading\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith('notebooks'):\n",
    "    src_path = os.path.abspath(os.path.join(current_dir, '..', 'src'))\n",
    "    data_dir = '../data'\n",
    "else:\n",
    "    src_path = os.path.abspath(os.path.join(current_dir, 'src'))\n",
    "    data_dir = 'data'\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from features import FeatureEngineer\n",
    "from models import ForecastingModels\n",
    "from optimization import InventoryOptimizer\n",
    "\n",
    "print(\"Loading and preparing data...\")\n",
    "df = pd.read_csv(f'{data_dir}/sales.csv', parse_dates=['date']).merge(\n",
    "    pd.read_csv(f'{data_dir}/products.csv'), on='product_id', how='left').merge(\n",
    "    pd.read_csv(f'{data_dir}/stores.csv'), on='store_id', how='left').merge(\n",
    "    pd.read_csv(f'{data_dir}/promotions.csv', parse_dates=['date']), on='date', how='left')\n",
    "\n",
    "df['actual_sales'] = df['sales_quantity']\n",
    "df.loc[df['is_stockout'] == 1, 'actual_sales'] = np.nan\n",
    "df['imputed_sales'] = df.groupby(['store_id', 'product_id'])['actual_sales'].transform(lambda x: x.interpolate(method='linear', limit_direction='both')).bfill().fillna(0)\n",
    "\n",
    "fe = FeatureEngineer()\n",
    "df_featured = fe.run_pipeline(df)\n",
    "print(f\"Data ready. Shape: {df_featured.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa71553-99df-4c69-ac81-b152a89404ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Walk-Forward Cross-Validation...\n",
      "\n",
      "--- Fold 1 ---\n",
      "Training up to: 2024-07-23 | Testing: 2024-07-24 to 2025-01-14\n",
      "Fold 1 Ensemble Metrics: {'MAE': 7.14, 'RMSE': np.float64(12.21), 'MAPE (%)': np.float64(64878.69)}\n",
      "\n",
      "--- Fold 2 ---\n",
      "Training up to: 2025-01-14 | Testing: 2025-01-15 to 2025-07-08\n",
      "Fold 2 Ensemble Metrics: {'MAE': 7.92, 'RMSE': np.float64(16.12), 'MAPE (%)': np.float64(85662.68)}\n",
      "\n",
      "--- Fold 3 ---\n",
      "Training up to: 2025-07-08 | Testing: 2025-07-09 to 2025-12-30\n",
      "Fold 3 Ensemble Metrics: {'MAE': 6.84, 'RMSE': np.float64(12.28), 'MAPE (%)': np.float64(90768.49)}\n",
      "\n",
      "‚úÖ Historical performance saved to ../data/historical_performance.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Walk-Forward Cross Validation & Historical Tracking\n",
    "modeler = ForecastingModels()\n",
    "\n",
    "# We will use 3 expanding windows to simulate real-world weekly/monthly retraining\n",
    "splits = modeler.walk_forward_split(df_featured, n_splits=3)\n",
    "historical_results = []\n",
    "\n",
    "print(\"üöÄ Starting Walk-Forward Cross-Validation...\")\n",
    "\n",
    "for fold, (train_df, test_df) in enumerate(splits):\n",
    "    print(f\"\\n--- Fold {fold + 1} ---\")\n",
    "    print(f\"Training up to: {train_df['date'].max().date()} | Testing: {test_df['date'].min().date()} to {test_df['date'].max().date()}\")\n",
    "    \n",
    "    # 1. Train & Predict XGBoost\n",
    "    modeler.train_xgboost(train_df)\n",
    "    xgb_preds, xgb_lower, xgb_upper = modeler.predict_xgboost(test_df)\n",
    "    test_df['xgb_forecast'] = xgb_preds\n",
    "    \n",
    "    # 2. Train & Predict Statistical Baseline (Routed by Segment)\n",
    "    es_preds = []\n",
    "    unique_pairs = test_df[['store_id', 'product_id', 'demand_type']].drop_duplicates()\n",
    "    \n",
    "    for _, row in unique_pairs.iterrows():\n",
    "        s_id, p_id, d_type = row['store_id'], row['product_id'], row['demand_type']\n",
    "        train_series = train_df[(train_df['store_id'] == s_id) & (train_df['product_id'] == p_id)].set_index('date')['imputed_sales']\n",
    "        test_len = len(test_df[(test_df['store_id'] == s_id) & (test_df['product_id'] == p_id)])\n",
    "        \n",
    "        # This now uses Croston's for intermittent, and ES for fast-moving\n",
    "        preds = modeler.train_predict_statistical(train_series, test_len, demand_type=d_type)\n",
    "        \n",
    "        temp_df = pd.DataFrame({\n",
    "            'date': test_df[(test_df['store_id'] == s_id) & (test_df['product_id'] == p_id)]['date'],\n",
    "            'store_id': s_id, 'product_id': p_id, 'stat_forecast': preds\n",
    "        })\n",
    "        es_preds.append(temp_df)\n",
    "    \n",
    "    stat_results = pd.concat(es_preds)\n",
    "    test_df = test_df.merge(stat_results, on=['date', 'store_id', 'product_id'], how='left')\n",
    "    \n",
    "    # 3. Create the Ensemble (Average of ML and Statistical)\n",
    "    test_df['ensemble_forecast'] = (test_df['xgb_forecast'] + test_df['stat_forecast']) / 2\n",
    "    \n",
    "    metrics = modeler.calculate_metrics(test_df['imputed_sales'], test_df['ensemble_forecast'])\n",
    "    print(f\"Fold {fold + 1} Ensemble Metrics: {metrics}\")\n",
    "    \n",
    "    # Save results to build a historical track record\n",
    "    historical_results.append(test_df[['date', 'store_id', 'product_id', 'demand_type', 'imputed_sales', 'ensemble_forecast']])\n",
    "\n",
    "# Export historical performance for the dashboard\n",
    "df_history = pd.concat(historical_results)\n",
    "df_history.to_csv(f'{data_dir}/historical_performance.csv', index=False)\n",
    "print(f\"\\n‚úÖ Historical performance saved to {data_dir}/historical_performance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd31c425-0369-4fd2-b98f-48439e4ab55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Training Final Global Model for Future Projections...\n",
      "\n",
      "--- Final 60-Day Forward Look Evaluation ---\n",
      "Segment: Fast-Moving | MAPE: 12.1%\n",
      "Segment: Seasonal | MAPE: 12.26%\n",
      "Segment: Intermittent | MAPE: 449865.93%\n",
      "\n",
      "‚öôÔ∏è Running Inventory Optimization Module...\n",
      "‚úÖ Optimization complete. Future recommendations saved to ../data/final_inventory_recommendations.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Final Training & Inventory Optimization\n",
    "# We reserve the last 60 days to act as our \"Future\" projection for the dashboard\n",
    "split_date = df_featured['date'].max() - pd.Timedelta(days=60)\n",
    "train_df = df_featured[df_featured['date'] < split_date].copy()\n",
    "test_df = df_featured[df_featured['date'] >= split_date].copy()\n",
    "\n",
    "print(\"\\nüìà Training Final Global Model for Future Projections...\")\n",
    "modeler.train_xgboost(train_df)\n",
    "xgb_preds, xgb_lower, xgb_upper = modeler.predict_xgboost(test_df)\n",
    "test_df['xgb_forecast'] = xgb_preds\n",
    "test_df['xgb_lower_bound'] = xgb_lower\n",
    "test_df['xgb_upper_bound'] = xgb_upper\n",
    "\n",
    "# Statistical baseline\n",
    "es_preds = []\n",
    "unique_pairs = test_df[['store_id', 'product_id', 'demand_type']].drop_duplicates()\n",
    "for _, row in unique_pairs.iterrows():\n",
    "    s_id, p_id, d_type = row['store_id'], row['product_id'], row['demand_type']\n",
    "    train_series = train_df[(train_df['store_id'] == s_id) & (train_df['product_id'] == p_id)].set_index('date')['imputed_sales']\n",
    "    test_len = len(test_df[(test_df['store_id'] == s_id) & (test_df['product_id'] == p_id)])\n",
    "    \n",
    "    preds = modeler.train_predict_statistical(train_series, test_len, demand_type=d_type)\n",
    "    temp_df = pd.DataFrame({'date': test_df[(test_df['store_id'] == s_id) & (test_df['product_id'] == p_id)]['date'],\n",
    "                            'store_id': s_id, 'product_id': p_id, 'stat_forecast': preds})\n",
    "    es_preds.append(temp_df)\n",
    "\n",
    "stat_results = pd.concat(es_preds)\n",
    "test_df = test_df.merge(stat_results, on=['date', 'store_id', 'product_id'], how='left')\n",
    "test_df['ensemble_forecast'] = (test_df['xgb_forecast'] + test_df['stat_forecast']) / 2\n",
    "\n",
    "# Final Segmentation Evaluation\n",
    "print(\"\\n--- Final 60-Day Forward Look Evaluation ---\")\n",
    "for segment in test_df['demand_type'].unique():\n",
    "    segment_data = test_df[test_df['demand_type'] == segment]\n",
    "    metrics = modeler.calculate_metrics(segment_data['imputed_sales'], segment_data['ensemble_forecast'])\n",
    "    print(f\"Segment: {segment} | MAPE: {metrics['MAPE (%)']}%\")\n",
    "\n",
    "# Inventory Optimization\n",
    "print(\"\\n‚öôÔ∏è Running Inventory Optimization Module...\")\n",
    "optimizer = InventoryOptimizer(lead_time_days=3, holding_cost_annual_rate=0.2, stockout_penalty_per_unit=15)\n",
    "\n",
    "# Pass in the test dataframe and the mathematically calculated residual_std\n",
    "df_inventory = optimizer.generate_recommendations(test_df, modeler.residual_std)\n",
    "\n",
    "# Append the prediction intervals so the dashboard can plot them\n",
    "df_inventory['lower_bound'] = test_df['xgb_lower_bound']\n",
    "df_inventory['upper_bound'] = test_df['xgb_upper_bound']\n",
    "\n",
    "df_inventory.to_csv(f'{data_dir}/final_inventory_recommendations.csv', index=False)\n",
    "print(f\"‚úÖ Optimization complete. Future recommendations saved to {data_dir}/final_inventory_recommendations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7971d24-2c44-40c4-b98f-a83f9286ab76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
